{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96d8308a-26b3-401e-a67b-e420c3e81a46",
   "metadata": {},
   "source": [
    "# Machine Learning Final Project  \n",
    "\n",
    "> 作者: 吳孟維 0816120  \n",
    "> Github Link: https://github.com/wumengwei0213/CS_CS20024_final_project  \n",
    "> Reference:   \n",
    "    https://www.kaggle.com/competitions/tabular-playground-series-aug-2022/discussion/349385  \n",
    "    https://www.kaggle.com/code/johnybhiduri/tabular-playground-series-keras  \n",
    "\n",
    "## Brief Intro.  \n",
    "    After researching some discussion on the Kaggle, I have breif concept of this competition. I decide to design the NN model by myself in order to treat this project as a self-traing and strengthen my skill in machine learning region. With looking into the data, I found that feature \"loading\" has a great relationship with the goal. And the features that is categorical are not much assosiate with the goal, so I decided to drop these feature to focus on the numerial features. The crux that I can pass the baseline is adding \"model assembling\" at the end of training model. I chose models that got top-5 score in the Kaggle private leaderboard and re-made the prediction.\n",
    "    \n",
    "## Model Architecture  \n",
    "![](https://i.imgur.com/DZCUs6I.png)  \n",
    "### Hyperparameters  \n",
    "> optimizer = Adam with learning_rate=0.001  \n",
    "> loss = 'binary_crossentropy'  \n",
    "> validation_split = 0.3  \n",
    "> batch_size = 128  \n",
    "> epochs = 10  \n",
    "\n",
    "## Summary\n",
    "\n",
    "I got 0.59022 in the end.\n",
    "\n",
    "| Name         | Private Score | Public Score |\n",
    "| ------------------ |---------------- | -------------- |\n",
    "| inference.csv   |     0.59022         |      0.5803       |  \n",
    "\n",
    "![](https://i.imgur.com/2GD780n.png)\n",
    "\n",
    "\n",
    "## Methodology \n",
    "\n",
    "### Import Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f9938ae-ea50-458d-95dc-8ea87cf6d123",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde89f2c-0549-4fdc-8d6f-3c74cead0e75",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "According to the research, adding columns that corresponds to if there is NA value in the features \"measurement 3-6\" can improve AUC value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e197b19a-0504-49a9-9cf4-2c21097cd0ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_code</th>\n",
       "      <th>loading</th>\n",
       "      <th>attribute_0</th>\n",
       "      <th>attribute_1</th>\n",
       "      <th>attribute_2</th>\n",
       "      <th>attribute_3</th>\n",
       "      <th>measurement_0</th>\n",
       "      <th>measurement_1</th>\n",
       "      <th>measurement_2</th>\n",
       "      <th>measurement_3</th>\n",
       "      <th>measurement_4</th>\n",
       "      <th>measurement_5</th>\n",
       "      <th>measurement_6</th>\n",
       "      <th>measurement_7</th>\n",
       "      <th>measurement_8</th>\n",
       "      <th>measurement_9</th>\n",
       "      <th>measurement_10</th>\n",
       "      <th>measurement_11</th>\n",
       "      <th>measurement_12</th>\n",
       "      <th>measurement_13</th>\n",
       "      <th>measurement_14</th>\n",
       "      <th>measurement_15</th>\n",
       "      <th>measurement_16</th>\n",
       "      <th>measurement_17</th>\n",
       "      <th>failure</th>\n",
       "      <th>miss3</th>\n",
       "      <th>miss4</th>\n",
       "      <th>miss5</th>\n",
       "      <th>miss6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>80.10</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_8</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>18.040</td>\n",
       "      <td>12.518</td>\n",
       "      <td>15.748</td>\n",
       "      <td>19.292</td>\n",
       "      <td>11.739</td>\n",
       "      <td>20.155</td>\n",
       "      <td>10.672</td>\n",
       "      <td>15.859</td>\n",
       "      <td>17.594</td>\n",
       "      <td>15.193</td>\n",
       "      <td>15.029</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.034</td>\n",
       "      <td>14.684</td>\n",
       "      <td>764.100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>84.89</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_8</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>18.213</td>\n",
       "      <td>11.540</td>\n",
       "      <td>17.717</td>\n",
       "      <td>17.893</td>\n",
       "      <td>12.748</td>\n",
       "      <td>17.889</td>\n",
       "      <td>12.448</td>\n",
       "      <td>17.947</td>\n",
       "      <td>17.915</td>\n",
       "      <td>11.755</td>\n",
       "      <td>14.732</td>\n",
       "      <td>15.425</td>\n",
       "      <td>14.395</td>\n",
       "      <td>15.631</td>\n",
       "      <td>682.057</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>82.43</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_8</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>18.057</td>\n",
       "      <td>11.652</td>\n",
       "      <td>16.738</td>\n",
       "      <td>18.240</td>\n",
       "      <td>12.718</td>\n",
       "      <td>18.288</td>\n",
       "      <td>12.715</td>\n",
       "      <td>15.607</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.798</td>\n",
       "      <td>16.711</td>\n",
       "      <td>18.631</td>\n",
       "      <td>14.094</td>\n",
       "      <td>17.946</td>\n",
       "      <td>663.376</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>101.07</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_8</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>17.295</td>\n",
       "      <td>11.188</td>\n",
       "      <td>18.576</td>\n",
       "      <td>18.339</td>\n",
       "      <td>12.583</td>\n",
       "      <td>19.060</td>\n",
       "      <td>12.471</td>\n",
       "      <td>16.346</td>\n",
       "      <td>18.377</td>\n",
       "      <td>10.020</td>\n",
       "      <td>15.250</td>\n",
       "      <td>15.562</td>\n",
       "      <td>16.154</td>\n",
       "      <td>17.172</td>\n",
       "      <td>826.282</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>188.06</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_8</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>19.346</td>\n",
       "      <td>12.950</td>\n",
       "      <td>16.990</td>\n",
       "      <td>15.746</td>\n",
       "      <td>11.306</td>\n",
       "      <td>18.093</td>\n",
       "      <td>10.337</td>\n",
       "      <td>17.082</td>\n",
       "      <td>19.932</td>\n",
       "      <td>12.428</td>\n",
       "      <td>16.182</td>\n",
       "      <td>12.760</td>\n",
       "      <td>13.153</td>\n",
       "      <td>16.412</td>\n",
       "      <td>579.885</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id product_code  loading attribute_0 attribute_1  attribute_2  attribute_3  \\\n",
       "0   0            A    80.10  material_7  material_8            9            5   \n",
       "1   1            A    84.89  material_7  material_8            9            5   \n",
       "2   2            A    82.43  material_7  material_8            9            5   \n",
       "3   3            A   101.07  material_7  material_8            9            5   \n",
       "4   4            A   188.06  material_7  material_8            9            5   \n",
       "\n",
       "   measurement_0  measurement_1  measurement_2  measurement_3  measurement_4  \\\n",
       "0              7              8              4         18.040         12.518   \n",
       "1             14              3              3         18.213         11.540   \n",
       "2             12              1              5         18.057         11.652   \n",
       "3             13              2              6         17.295         11.188   \n",
       "4              9              2              8         19.346         12.950   \n",
       "\n",
       "   measurement_5  measurement_6  measurement_7  measurement_8  measurement_9  \\\n",
       "0         15.748         19.292         11.739         20.155         10.672   \n",
       "1         17.717         17.893         12.748         17.889         12.448   \n",
       "2         16.738         18.240         12.718         18.288         12.715   \n",
       "3         18.576         18.339         12.583         19.060         12.471   \n",
       "4         16.990         15.746         11.306         18.093         10.337   \n",
       "\n",
       "   measurement_10  measurement_11  measurement_12  measurement_13  \\\n",
       "0          15.859          17.594          15.193          15.029   \n",
       "1          17.947          17.915          11.755          14.732   \n",
       "2          15.607             NaN          13.798          16.711   \n",
       "3          16.346          18.377          10.020          15.250   \n",
       "4          17.082          19.932          12.428          16.182   \n",
       "\n",
       "   measurement_14  measurement_15  measurement_16  measurement_17  failure  \\\n",
       "0             NaN          13.034          14.684         764.100        0   \n",
       "1          15.425          14.395          15.631         682.057        0   \n",
       "2          18.631          14.094          17.946         663.376        0   \n",
       "3          15.562          16.154          17.172         826.282        0   \n",
       "4          12.760          13.153          16.412         579.885        0   \n",
       "\n",
       "   miss3  miss4  miss5  miss6  \n",
       "0      0      0      0      0  \n",
       "1      0      0      0      0  \n",
       "2      0      0      0      0  \n",
       "3      0      0      0      0  \n",
       "4      0      0      0      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "pd.set_option('display.max_columns',None)\n",
    "\n",
    "train['miss3'] = train['measurement_3'].isna().astype(int)*32\n",
    "train['miss4'] = train['measurement_4'].isna().astype(int)*32\n",
    "train['miss5'] = train['measurement_5'].isna().astype(int)*32\n",
    "train['miss6'] = train['measurement_6'].isna().astype(int)*32\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bdc2c5-53cd-4f55-8bbe-356fe3ebb058",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data Prepoccessing\n",
    "- Pick the beneficial features for training  \n",
    "- Replace NA with mean value of the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dd2dddb-a6b9-4bda-9beb-f5b80891036b",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkColumns = ['loading','measurement_0','measurement_1','measurement_2','measurement_3','measurement_4','measurement_5','measurement_6','measurement_7','measurement_8','measurement_9','measurement_10','measurement_11','measurement_12','measurement_13','measurement_14','measurement_15','measurement_16','miss3','miss4','miss5']\n",
    "\n",
    "train_df = train.copy()\n",
    "for i in checkColumns :\n",
    "    m = train_df[i].mean()\n",
    "    train_df[i] = train_df[i].fillna(m)\n",
    "Y = train_df['failure']\n",
    "X = train_df[checkColumns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ee3a17-dc70-43ae-b010-b9b075aacd41",
   "metadata": {},
   "source": [
    "### Deprecated Method\n",
    "\n",
    "> Add RandomOverSampler to make the data more balance\n",
    "\n",
    "#### Result  \n",
    "\n",
    "> It did not enhance the score, so I remove it.\n",
    "\n",
    "```\n",
    "x_train,x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.25, shuffle = True, random_state = 144)\n",
    "num_samples = int(y_train.value_counts().mean())\n",
    "majority_ind = y_train[y_train == 0.0].index\n",
    "samples_to_drop = y_train[majority_ind].sample(num_samples, random_state = 1).index\n",
    "x_train = x_train.drop(samples_to_drop, axis = 0)\n",
    "y_train = y_train.drop(samples_to_drop, axis = 0)\n",
    "over_sampler = RandomOverSampler(random_state = 1)\n",
    "x_train,y_train = over_sampler.fit_resample(x_train, y_train)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = pd.DataFrame(scaler.transform(x_train), columns = x_train.columns, index = x_train.index)\n",
    "x_test = pd.DataFrame(scaler.transform(x_test), columns = x_test.columns, index = x_test.index)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86bd5b0-323d-448a-8c8c-89737c56533c",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f8a976e-7163-4102-8502-c580c97bc708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loading</th>\n",
       "      <th>measurement_0</th>\n",
       "      <th>measurement_1</th>\n",
       "      <th>measurement_2</th>\n",
       "      <th>measurement_3</th>\n",
       "      <th>measurement_4</th>\n",
       "      <th>measurement_5</th>\n",
       "      <th>measurement_6</th>\n",
       "      <th>measurement_7</th>\n",
       "      <th>measurement_8</th>\n",
       "      <th>measurement_9</th>\n",
       "      <th>measurement_10</th>\n",
       "      <th>measurement_11</th>\n",
       "      <th>measurement_12</th>\n",
       "      <th>measurement_13</th>\n",
       "      <th>measurement_14</th>\n",
       "      <th>measurement_15</th>\n",
       "      <th>measurement_16</th>\n",
       "      <th>miss3</th>\n",
       "      <th>miss4</th>\n",
       "      <th>miss5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22216</th>\n",
       "      <td>109.270000</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>19.247</td>\n",
       "      <td>11.069000</td>\n",
       "      <td>17.675</td>\n",
       "      <td>17.781</td>\n",
       "      <td>10.855000</td>\n",
       "      <td>18.867000</td>\n",
       "      <td>11.199</td>\n",
       "      <td>17.508</td>\n",
       "      <td>21.108000</td>\n",
       "      <td>11.264</td>\n",
       "      <td>15.064000</td>\n",
       "      <td>16.612</td>\n",
       "      <td>16.558</td>\n",
       "      <td>13.381</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18029</th>\n",
       "      <td>160.020000</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>18.546</td>\n",
       "      <td>10.638000</td>\n",
       "      <td>16.686</td>\n",
       "      <td>17.536</td>\n",
       "      <td>12.078000</td>\n",
       "      <td>18.988000</td>\n",
       "      <td>10.065</td>\n",
       "      <td>18.266</td>\n",
       "      <td>18.944000</td>\n",
       "      <td>11.034</td>\n",
       "      <td>14.011000</td>\n",
       "      <td>17.752</td>\n",
       "      <td>15.723</td>\n",
       "      <td>13.628</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17046</th>\n",
       "      <td>162.310000</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>18.851</td>\n",
       "      <td>12.204000</td>\n",
       "      <td>16.031</td>\n",
       "      <td>16.599</td>\n",
       "      <td>12.715000</td>\n",
       "      <td>20.078000</td>\n",
       "      <td>12.471</td>\n",
       "      <td>18.242</td>\n",
       "      <td>21.241000</td>\n",
       "      <td>13.247</td>\n",
       "      <td>13.909000</td>\n",
       "      <td>15.049</td>\n",
       "      <td>14.945</td>\n",
       "      <td>16.207</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3397</th>\n",
       "      <td>118.510000</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15.033</td>\n",
       "      <td>11.413000</td>\n",
       "      <td>16.297</td>\n",
       "      <td>17.797</td>\n",
       "      <td>10.999000</td>\n",
       "      <td>19.133000</td>\n",
       "      <td>12.864</td>\n",
       "      <td>15.493</td>\n",
       "      <td>19.172085</td>\n",
       "      <td>14.546</td>\n",
       "      <td>15.809000</td>\n",
       "      <td>14.545</td>\n",
       "      <td>16.825</td>\n",
       "      <td>20.565</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16532</th>\n",
       "      <td>147.620000</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>18.490</td>\n",
       "      <td>11.731988</td>\n",
       "      <td>20.569</td>\n",
       "      <td>17.462</td>\n",
       "      <td>13.069000</td>\n",
       "      <td>19.024714</td>\n",
       "      <td>11.224</td>\n",
       "      <td>18.111</td>\n",
       "      <td>21.010000</td>\n",
       "      <td>12.004</td>\n",
       "      <td>16.814000</td>\n",
       "      <td>17.122</td>\n",
       "      <td>14.093</td>\n",
       "      <td>14.548</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17830</th>\n",
       "      <td>86.650000</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>16.651</td>\n",
       "      <td>13.058000</td>\n",
       "      <td>18.441</td>\n",
       "      <td>18.240</td>\n",
       "      <td>11.997000</td>\n",
       "      <td>20.829000</td>\n",
       "      <td>11.932</td>\n",
       "      <td>15.203</td>\n",
       "      <td>17.686000</td>\n",
       "      <td>10.829</td>\n",
       "      <td>14.074000</td>\n",
       "      <td>15.362</td>\n",
       "      <td>16.102</td>\n",
       "      <td>15.175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7384</th>\n",
       "      <td>109.450000</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>18.227</td>\n",
       "      <td>11.841000</td>\n",
       "      <td>17.107</td>\n",
       "      <td>18.150</td>\n",
       "      <td>11.910000</td>\n",
       "      <td>19.024714</td>\n",
       "      <td>12.298</td>\n",
       "      <td>15.969</td>\n",
       "      <td>16.164000</td>\n",
       "      <td>10.801</td>\n",
       "      <td>13.631000</td>\n",
       "      <td>14.734</td>\n",
       "      <td>13.268</td>\n",
       "      <td>17.126</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22394</th>\n",
       "      <td>127.826233</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>18.029</td>\n",
       "      <td>9.568000</td>\n",
       "      <td>17.183</td>\n",
       "      <td>16.258</td>\n",
       "      <td>12.597000</td>\n",
       "      <td>18.625000</td>\n",
       "      <td>11.518</td>\n",
       "      <td>15.229</td>\n",
       "      <td>18.614000</td>\n",
       "      <td>9.435</td>\n",
       "      <td>14.862000</td>\n",
       "      <td>16.019</td>\n",
       "      <td>13.750</td>\n",
       "      <td>16.952</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>88.290000</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>18.092</td>\n",
       "      <td>12.160000</td>\n",
       "      <td>18.499</td>\n",
       "      <td>16.669</td>\n",
       "      <td>10.590000</td>\n",
       "      <td>19.776000</td>\n",
       "      <td>11.568</td>\n",
       "      <td>15.155</td>\n",
       "      <td>19.605000</td>\n",
       "      <td>10.535</td>\n",
       "      <td>15.652904</td>\n",
       "      <td>14.368</td>\n",
       "      <td>15.091</td>\n",
       "      <td>16.606</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25959</th>\n",
       "      <td>123.340000</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>18.669</td>\n",
       "      <td>10.919000</td>\n",
       "      <td>17.101</td>\n",
       "      <td>17.604</td>\n",
       "      <td>11.716624</td>\n",
       "      <td>17.534000</td>\n",
       "      <td>12.351</td>\n",
       "      <td>15.291</td>\n",
       "      <td>21.407000</td>\n",
       "      <td>14.153</td>\n",
       "      <td>16.939000</td>\n",
       "      <td>15.676</td>\n",
       "      <td>14.910</td>\n",
       "      <td>18.716</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19927 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          loading  measurement_0  measurement_1  measurement_2  measurement_3  \\\n",
       "22216  109.270000              1             18              1         19.247   \n",
       "18029  160.020000              3              7             13         18.546   \n",
       "17046  162.310000              8             13             12         18.851   \n",
       "3397   118.510000             11              2              2         15.033   \n",
       "16532  147.620000              4             10              9         18.490   \n",
       "...           ...            ...            ...            ...            ...   \n",
       "17830   86.650000              5             11             10         16.651   \n",
       "7384   109.450000              7             13              5         18.227   \n",
       "22394  127.826233              6             11              5         18.029   \n",
       "1468    88.290000              9              5              3         18.092   \n",
       "25959  123.340000              9              7              5         18.669   \n",
       "\n",
       "       measurement_4  measurement_5  measurement_6  measurement_7  \\\n",
       "22216      11.069000         17.675         17.781      10.855000   \n",
       "18029      10.638000         16.686         17.536      12.078000   \n",
       "17046      12.204000         16.031         16.599      12.715000   \n",
       "3397       11.413000         16.297         17.797      10.999000   \n",
       "16532      11.731988         20.569         17.462      13.069000   \n",
       "...              ...            ...            ...            ...   \n",
       "17830      13.058000         18.441         18.240      11.997000   \n",
       "7384       11.841000         17.107         18.150      11.910000   \n",
       "22394       9.568000         17.183         16.258      12.597000   \n",
       "1468       12.160000         18.499         16.669      10.590000   \n",
       "25959      10.919000         17.101         17.604      11.716624   \n",
       "\n",
       "       measurement_8  measurement_9  measurement_10  measurement_11  \\\n",
       "22216      18.867000         11.199          17.508       21.108000   \n",
       "18029      18.988000         10.065          18.266       18.944000   \n",
       "17046      20.078000         12.471          18.242       21.241000   \n",
       "3397       19.133000         12.864          15.493       19.172085   \n",
       "16532      19.024714         11.224          18.111       21.010000   \n",
       "...              ...            ...             ...             ...   \n",
       "17830      20.829000         11.932          15.203       17.686000   \n",
       "7384       19.024714         12.298          15.969       16.164000   \n",
       "22394      18.625000         11.518          15.229       18.614000   \n",
       "1468       19.776000         11.568          15.155       19.605000   \n",
       "25959      17.534000         12.351          15.291       21.407000   \n",
       "\n",
       "       measurement_12  measurement_13  measurement_14  measurement_15  \\\n",
       "22216          11.264       15.064000          16.612          16.558   \n",
       "18029          11.034       14.011000          17.752          15.723   \n",
       "17046          13.247       13.909000          15.049          14.945   \n",
       "3397           14.546       15.809000          14.545          16.825   \n",
       "16532          12.004       16.814000          17.122          14.093   \n",
       "...               ...             ...             ...             ...   \n",
       "17830          10.829       14.074000          15.362          16.102   \n",
       "7384           10.801       13.631000          14.734          13.268   \n",
       "22394           9.435       14.862000          16.019          13.750   \n",
       "1468           10.535       15.652904          14.368          15.091   \n",
       "25959          14.153       16.939000          15.676          14.910   \n",
       "\n",
       "       measurement_16  miss3  miss4  miss5  \n",
       "22216          13.381      0      0      0  \n",
       "18029          13.628      0      0      0  \n",
       "17046          16.207      0      0      0  \n",
       "3397           20.565      0      0      0  \n",
       "16532          14.548      0     32      0  \n",
       "...               ...    ...    ...    ...  \n",
       "17830          15.175      0      0      0  \n",
       "7384           17.126      0      0      0  \n",
       "22394          16.952      0      0      0  \n",
       "1468           16.606      0      0      0  \n",
       "25959          18.716      0      0      0  \n",
       "\n",
       "[19927 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.25, shuffle = True, random_state = 144)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59d4e59-da8b-4710-a1e1-c0e2da5963d5",
   "metadata": {},
   "source": [
    "### Prediction Data Generating and Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32d3f7f9-0498-4051-bdd0-84752c950bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outp(auc) :\n",
    "    test = pd.read_csv('test.csv')\n",
    "    pd_id = test['id']\n",
    "\n",
    "    test['miss3'] = test['measurement_3'].isna().astype(int)*32\n",
    "    test['miss4'] = test['measurement_4'].isna().astype(int)*32\n",
    "    test['miss5'] = test['measurement_5'].isna().astype(int)*32\n",
    "    test['miss6'] = test['measurement_6'].isna().astype(int)*32\n",
    "\n",
    "    for i in checkColumns :\n",
    "        m = test[i].mean()\n",
    "        test[i] = test[i].fillna(m)\n",
    "    test = test[checkColumns]\n",
    "\n",
    "    predictions = model.predict(test)\n",
    "    predictions = pd.DataFrame(predictions, columns=['failure'])\n",
    "    out = pd.concat([pd_id, predictions],axis=1)\n",
    "    out.to_csv(f'save/out{auc}.csv',index=False)\n",
    "    model.save(f'save/model_{auc}.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b021ee-d3e1-4f46-8454-faeb5a8cfae5",
   "metadata": {},
   "source": [
    "### Building Model and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0dbfbb0-004f-4c6f-b3ce-53d891bfef2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "109/109 [==============================] - 8s 11ms/step - loss: 0.5679 - accuracy: 0.7529 - auc: 0.5240 - val_loss: 0.5555 - val_accuracy: 0.7869 - val_auc: 0.5746\n",
      "Epoch 2/10\n",
      "109/109 [==============================] - 1s 7ms/step - loss: 0.5383 - accuracy: 0.7772 - auc: 0.5376 - val_loss: 0.5141 - val_accuracy: 0.7919 - val_auc: 0.5639\n",
      "Epoch 3/10\n",
      "109/109 [==============================] - 1s 7ms/step - loss: 0.5282 - accuracy: 0.7828 - auc: 0.5483 - val_loss: 0.5145 - val_accuracy: 0.7919 - val_auc: 0.5683\n",
      "Epoch 4/10\n",
      "109/109 [==============================] - 1s 7ms/step - loss: 0.5276 - accuracy: 0.7841 - auc: 0.5490 - val_loss: 0.5063 - val_accuracy: 0.7918 - val_auc: 0.5727\n",
      "Epoch 5/10\n",
      "109/109 [==============================] - 1s 7ms/step - loss: 0.5244 - accuracy: 0.7833 - auc: 0.5558 - val_loss: 0.5064 - val_accuracy: 0.7918 - val_auc: 0.5813\n",
      "Epoch 6/10\n",
      "109/109 [==============================] - 1s 8ms/step - loss: 0.5235 - accuracy: 0.7843 - auc: 0.5522 - val_loss: 0.5064 - val_accuracy: 0.7911 - val_auc: 0.5712\n",
      "Epoch 7/10\n",
      "109/109 [==============================] - 1s 7ms/step - loss: 0.5204 - accuracy: 0.7842 - auc: 0.5590 - val_loss: 0.5053 - val_accuracy: 0.7903 - val_auc: 0.5713\n",
      "Epoch 8/10\n",
      "109/109 [==============================] - 1s 7ms/step - loss: 0.5201 - accuracy: 0.7843 - auc: 0.5637 - val_loss: 0.5051 - val_accuracy: 0.7916 - val_auc: 0.5789\n",
      "Epoch 9/10\n",
      "109/109 [==============================] - 1s 7ms/step - loss: 0.5203 - accuracy: 0.7848 - auc: 0.5556 - val_loss: 0.5045 - val_accuracy: 0.7919 - val_auc: 0.5778\n",
      "Epoch 10/10\n",
      "109/109 [==============================] - 1s 7ms/step - loss: 0.5177 - accuracy: 0.7856 - auc: 0.5662 - val_loss: 0.5076 - val_accuracy: 0.7916 - val_auc: 0.5774\n",
      "[0.5746009349822998, 0.5639437437057495, 0.5682618021965027, 0.572697103023529, 0.581304132938385, 0.5712159872055054, 0.5713181495666504, 0.5789045095443726, 0.5777824521064758, 0.5773547887802124]\n",
      "Epoch 1/10\n",
      "109/109 [==============================] - 2s 8ms/step - loss: 0.5611 - accuracy: 0.7604 - auc: 0.5366 - val_loss: 0.5690 - val_accuracy: 0.7918 - val_auc: 0.4577\n",
      "Epoch 2/10\n",
      "109/109 [==============================] - 1s 7ms/step - loss: 0.5403 - accuracy: 0.7793 - auc: 0.5245 - val_loss: 0.5094 - val_accuracy: 0.7918 - val_auc: 0.5814\n",
      "Epoch 3/10\n",
      "109/109 [==============================] - 1s 7ms/step - loss: 0.5278 - accuracy: 0.7823 - auc: 0.5501 - val_loss: 0.5049 - val_accuracy: 0.7916 - val_auc: 0.5759\n",
      "Epoch 4/10\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 0.5260 - accuracy: 0.7832 - auc: 0.5535 - val_loss: 0.5065 - val_accuracy: 0.7918 - val_auc: 0.5638\n",
      "Epoch 5/10\n",
      "109/109 [==============================] - 1s 7ms/step - loss: 0.5241 - accuracy: 0.7829 - auc: 0.5514 - val_loss: 0.5068 - val_accuracy: 0.7894 - val_auc: 0.5804\n",
      "Epoch 6/10\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 0.5237 - accuracy: 0.7839 - auc: 0.5519 - val_loss: 0.5052 - val_accuracy: 0.7919 - val_auc: 0.5716\n",
      "Epoch 7/10\n",
      "109/109 [==============================] - 1s 6ms/step - loss: 0.5217 - accuracy: 0.7851 - auc: 0.5562 - val_loss: 0.5132 - val_accuracy: 0.7918 - val_auc: 0.5432\n",
      "Epoch 8/10\n",
      "109/109 [==============================] - 1s 7ms/step - loss: 0.5198 - accuracy: 0.7851 - auc: 0.5575 - val_loss: 0.5076 - val_accuracy: 0.7919 - val_auc: 0.5736\n",
      "Epoch 9/10\n",
      "109/109 [==============================] - 1s 7ms/step - loss: 0.5199 - accuracy: 0.7851 - auc: 0.5703 - val_loss: 0.5063 - val_accuracy: 0.7918 - val_auc: 0.5724\n",
      "Epoch 10/10\n",
      "109/109 [==============================] - 1s 7ms/step - loss: 0.5192 - accuracy: 0.7851 - auc: 0.5655 - val_loss: 0.5058 - val_accuracy: 0.7918 - val_auc: 0.5809\n",
      "[0.45770102739334106, 0.5813931822776794, 0.5758665800094604, 0.5637527108192444, 0.5804040431976318, 0.5715550780296326, 0.5431562066078186, 0.5736348032951355, 0.5723981857299805, 0.5808916687965393]\n",
      "650/650 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "while 1 :\n",
    "\n",
    "    inputs = tf.keras.Input(shape = (x_train.shape[1],))\n",
    "    x = tf.keras.layers.Normalization(axis=-1)(inputs)\n",
    "    x = tf.keras.layers.Dense(256, activation = 'relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.1)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(256, activation = 'relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(256, activation = 'relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(64, activation = 'relu')(x)\n",
    "    outputs = tf.keras.layers.Dense(1, activation = 'sigmoid')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs = inputs, outputs = outputs)\n",
    "    model.compile(\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss = 'binary_crossentropy',\n",
    "        metrics = [\n",
    "            'accuracy',\n",
    "            tf.keras.metrics.AUC(name = 'auc')\n",
    "        ]\n",
    "    )\n",
    "    history = model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        validation_split = 0.3,\n",
    "        batch_size = 128,\n",
    "        epochs = 10,\n",
    "    )\n",
    "\n",
    "    \n",
    "    print(history.history['val_auc'])\n",
    "    \n",
    "    if(history.history['val_auc'][-1] > 0.58) :\n",
    "        outp(str(round(history.history['val_auc'][-1],4)))\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44377290-b2bc-4e20-8738-4c5134b354ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 21)]              0         \n",
      "                                                                 \n",
      " normalization_1 (Normalizat  (None, 21)               43        \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 256)               5632      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 156,844\n",
      "Trainable params: 155,265\n",
      "Non-trainable params: 1,579\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42779156-4d94-497b-a024-8fbdb7faaa20",
   "metadata": {},
   "source": [
    "### Model Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "908b5dd8-1f1c-4157-b5a6-410d376c4cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss : 50.8950%\n",
      "Test Accuracy : 78.729%\n",
      "Test AUC : 59.6999%\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test, y_test, verbose = 0)\n",
    "print('Test Loss : {:.4f}%'.format(results[0]*100))\n",
    "print('Test Accuracy : {:.3f}%'.format(results[1]*100))\n",
    "print('Test AUC : {:.4f}%'.format(results[2]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72dd42fb-9309-404d-b5d3-9c8d923ff655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/208 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.array(model.predict(x_test) >= 0.5, dtype = np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7bfcb4d-b068-4d05-a1bb-c90d05642014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Failure       0.79      1.00      0.88      5230\n",
      "     Success       0.00      0.00      0.00      1413\n",
      "\n",
      "    accuracy                           0.79      6643\n",
      "   macro avg       0.39      0.50      0.44      6643\n",
      "weighted avg       0.62      0.79      0.69      6643\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "clr = classification_report(y_test, y_pred, target_names = ['Failure', 'Success'])\n",
    "sns.heatmap(cm, annot = True, fmt = 'g', cbar = False, cmap = 'Blues')\n",
    "plt.xticks(ticks = (0.5, 1.5), labels = ['Failure', 'Success'])\n",
    "plt.yticks(ticks = (0.5, 1.5),labels = ['Failure', 'Success'])\n",
    "plt.show()\n",
    "print(f'Classification Report : \\n{clr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c2911e-7ca3-4250-b5bf-e8e13dbbd9cd",
   "metadata": {},
   "source": [
    "### Model Assembling\n",
    "\n",
    "- Choose models that got top-5 score in the Kaggle private leaderboard and re-made the prediction.\n",
    "\n",
    "![](https://i.imgur.com/Vv73Vry.png)\n",
    "\n",
    "- In the end, I chose the max ranking value to do the prediction in those prediction data after several experiments.\n",
    "\n",
    "![](https://i.imgur.com/w661ZeK.png)  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
